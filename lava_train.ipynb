{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize model\n",
      "iteration 0 ave reward -1.1199999999999999\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Qfunction.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3374211520>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Qfunction.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f3374211520>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 04:16:32.148827: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-08 04:16:32.170390: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994000000 Hz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "episodes = 1000  # number of episodes to run\n",
    "initialize = 300  # initial time steps before start updating\n",
    "\n",
    "from chain_mdp import ChainMDP\n",
    "from agent_lava import agent\n",
    "from lava_grid import ZigZag6x10\n",
    "# default setting\n",
    "max_steps = 100\n",
    "stochasticity = 0 # probability of the selected action failing and instead executing any of the remaining 3\n",
    "# recieve 1 at rightmost stae and recieve small reward at leftmost state\n",
    "env = ZigZag6x10(max_steps=max_steps, act_fail_prob=stochasticity, goal=(5, 9), numpy_state=False)\n",
    "agent = agent(load_model=None)\n",
    "s = env.reset()\n",
    "rrecord = []\n",
    "totalstep = 0\n",
    "for ite in range(episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    rsum = 0\n",
    "    while not done:\n",
    "        totalstep +=1\n",
    "        action = agent.action(obs)\n",
    "        next_obs,reward,done,info = env.step(action)\n",
    "        rsum += reward\n",
    "        try :\n",
    "            if obs == 0 :\n",
    "                if totalstep>initialize:\n",
    "                    agent.train(totalstep)\n",
    "                obs = next_obs    \n",
    "\n",
    "        except ValueError :\n",
    "            pass\n",
    "        experience = (obs,action,reward,next_obs,done)\n",
    "        agent.buffer.append(experience)\n",
    "\n",
    "        if totalstep>initialize:\n",
    "            agent.train(totalstep)\n",
    "        obs = next_obs\n",
    "                        \n",
    "################################################################################\n",
    "    ## DO NOT CHANGE THIS PART!\n",
    "    rrecord.append(rsum)\n",
    "    if ite % 200 == 0:\n",
    "        print('iteration {} ave reward {}'.format(ite, np.mean(rrecord[-10:])))\n",
    "    \n",
    "    ave100 = np.mean(rrecord[-100:])   \n",
    "    if  ave100 > 17.5:\n",
    "        print(\"Solved after %d episodes.\"%ite)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save(\"./saved_models/lava/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot [episode, reward] history\n",
    "x = [i+1 for i in range(len(rrecord))]\n",
    "plt.plot(x, rrecord)\n",
    "plt.title('episode rewards')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('rewards')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from lava_grid import ZigZag6x10\n",
    "from agent_lava import agent\n",
    "import random\n",
    "\n",
    "# default setting\n",
    "max_steps = 100\n",
    "stochasticity = 0 # probability of the selected action failing and instead executing any of the remaining 3\n",
    "no_render = True\n",
    "\n",
    "env = ZigZag6x10(max_steps=max_steps, act_fail_prob=stochasticity, goal=(5, 9), numpy_state=False)\n",
    "s = env.reset()\n",
    "done = False\n",
    "cum_reward = 0.0\n",
    "\n",
    "\"\"\" Your agent\"\"\"\n",
    "agent = agent()\n",
    "\n",
    "# moving costs -0.01, falling in lava -1, reaching goal +1\n",
    "# final reward is number_of_steps / max_steps\n",
    "while not done:\n",
    "    action = agent.action(s)\n",
    "    # action = random.randrange(4): random actions\n",
    "    ns, reward, done, _ = env.step(action)\n",
    "    cum_reward += reward\n",
    "    s = ns\n",
    "print(f\"total reward: {cum_reward}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b8ac3fc04880ec3c745ec33db7677d09628aa7e2e0c0a0338178b516357407b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rl_final')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
